\documentclass[../AlgebraQualSolutions.tex]{subfiles}

\begin{document}

\subsection{Linear Maps}

	\begin{prob}{S19.LA4}{S19.LA4}
		Let $V$ be the vector space of all $2 \times 2$ matrices and let 
			\[A = \begin{pmatrix} 2 & 0\\ 0 & 3 \end{pmatrix}. \]
		Let $T: V \to V$ be given by $T(B) = AB + BA$.

		\begin{enumerate}[(a)]
			\item Prove that $T$ is a linear map.
			\item Compute $T(B)$ when $B = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$.
			\item Find the eigenvalues and corresponding eigenspaces of $T$.
		\end{enumerate}
	\end{prob}

	\begin{proof}
		Let $B,C \in V$ and $\alpha \in \R$. Following from properties of matrix multiplication and addition,
			\[T(B + C) = A(B+C) + (B+C)A = AB + AC + BA + CA = T(B) + T(C).\]
		Likewise,
			\[T(\alpha B) = A(\alpha B) + (\alpha B)A = \alpha(AB +BA) = \alpha T(B).\]
	\end{proof}

	\begin{solution}
		\[T\left(\begin{pmatrix} a & b \\ c & d \end{pmatrix}\right) = \begin{pmatrix} 2a & 2b \\ 3c & 3d \end{pmatrix}.\]
	\end{solution}

	\begin{solution}
		Notice that $V$ is dimension 4 and so the sum of the dimensions  of the eigenspaces is at most 4. Upon inspection, we find that $\lambda = 2$ is an eigenvalue with an eigenspace basis given by $\left\{ \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \right\}$. Similarly, $\lambda = 3$ is an eigenvalue with eigenspace basis given by $\left\{ \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix} \right\}$. 
	\end{solution}

	\begin{prob}{F16.LA1, F14.LA1}{F14.LA1}
		Suppose that $T: U \to V$ is a linear transformation with $U$ and $V$ both finite-dimensional vector spaces. Prove that
			\[\dim(\ker(T)) + \dim(\rm{range}(T)) = \dim(U).\]
	\end{prob}

	\begin{proof}
		Suppose that $\dim(U)$ and $\dim(V)$ are both finite. In particular, any subspace of $U$ and $V$ is also finite dimensional. Let $\{v_1,\ldots, v_m\}$ be a basis for $\ker(T) \sq U$. Extend this collection to a basis $\beta = \{v_1,\ldots, v_m, w_1,\ldots, w_n\}$ of $U$. With this chosen basis, it follows that $\dim(\ker(T)) = m$ and $\dim(U) = m + n$. Thus we must show that $\dim(\range(T)) = n$.\\

		Let $Tu$ be an arbitrary element of $\range(T)$. Since $\beta$ is a basis for $U$, there exist scalars $a_1,\ldots, a_m$ and $b_1,\ldots,b_n$ such that
			\[u = a_1v_1 + \cdots + a_mv_m + b_1w_1 + \cdots + b_nw_n. \]
		By the linearity of $T$, this means that
			\[Tu = a_1Tv_1 + \cdots + a_mTv_m + b_1Tw_1 + \cdots + b_nTw_n = b_1Tw_1 + \cdots + b_nTw_n.\]
		The second equality follows as each $v_i \in \ker(T)$ and therefore $a_iTv_i = 0$. This means that $\{Tw_1,\ldots,Tw_n\}$ span $\range(T)$.\\

		To see that $\{Tw_1,\ldots,Tw_n\}$ is a linearly independent set, suppose that
			\[c_1Tw_1 + \cdots + c_nTw_n = 0.\]
		By linearity,
			\[T(c_1w_1 + \cdots + c_nw_n) = 0\]
		and so $c_1w_1 + \cdots + c_nw_n \in \ker(T)$. Choose scalars $d_1,\ldots, d_m$ such that
			\[c_1w_1 + \cdots + c_nw_n = d_1v_1 + \cdots + d_mv_m.\]
		Rearranging,
			\[c_1w_1 + \cdots + c_nw_n - d_1v_1 - \cdots - d_mv_m = 0.\]
		But, $\beta$ is a basis and so the collection of elements in $\beta$ is linearly independent. That is, $c_1 = \cdots = c_n = d_1 = \cdots = d_m = 0$. Therefore, $\{Tw_1,\ldots,Tw_n\}$ are linearly independent. As this is a linearly independent spanning set for $\range(T)$, $\dim(\range(T)) = n$ as desired.
	\end{proof}

	\begin{prob}{F12}{F12.LA2}
	Suppose that $V = X \oplus Y$ and define the projection $V \to X$ by $\alpha(v) = x$ where $v = x+y$.
	\begin{enumerate}[(a)]
	\item Prove that a necessary and sufficient condition for an endomorphism $T: V \to V$ to be a projection is that $T^2 = T$. Identify $X$ and $Y$ in the case that this condition is satisfied.
	\item Prove that projections $T_1$ and $T_2$ have the same range if and only if $T_1T_2 = T_2$ and $T_2T_1 = T_1$.
	\end{enumerate}
	\end{prob}

	\begin{proof}
		Suppose first that $T: V \to V$ is a projection map. That is, for any $v = x + y \in X \oplus Y = V$, $Tv = x$. Then,
			\[T^2v = T(T(x+y)) = T(x) = x = T(x+y) = Tv\]
		and therefore $T^2 = T$.\\

		Now assume that $T^2=T$. Let $v  \in V$. Observe that $v = (v - Tv) + Tv$. Applying $T$ to both sides yields the following set of equalities:
			\[Tv = T(v-Tv) + T^2v = T(v-Tv) + Tv\]
		implying that $T(v-Tv) =0$ and therefore $v-Tv \in \range(T)$. Because $Tv \in \range(T)$, $v \in \ns(T) + \range(T)$.\\
		
		To show that $\ns(T) + \range(T)$ is a direct sum, suppose that $0 = x + Tu \in \ns(T) + \range(T)$. Then,	
			\[0 = T(0) = Tx + T^2u = 0 + Tu = Tu \]
		and therefore $x = 0$ as well. Since $x = Tu = 0$, $\ns(T) + \range(T)$ is a direct sum. That is, $V = \range(T) \oplus \ns(T)$.\\

		Since $Tv \in \range(T)$ for any $v \in V$, $T$ is indeed a projection.
	\end{proof}

	\begin{proof}
		Suppose that $\range(T_1) = W = \range(T_2)$ with both $T_1$ and $T_2$ projections. Let $v \in V$ and suppose that $v = w + w'$ where $w \in W$. Then,
			\[T_1T_2v = T_1w = w = T_2v\]
		and similarly,
			\[T_2T_1v = T_2w = w = T_1v.\]
		Assume now that $T_1T_2 = T_2$ and $T_2T_1 = T_1$. Let $v \in V$ and consider $T_1v \in \range(T_1)$. Then,
			\[T_1v = T_2T_1v \in \range(T_2).\]
		Similarly,
			\[T_2v = T_1T_2v \in \range(T_1) \]
		implying that $\range(T_1) = \range(T_2)$.
	\end{proof}



\end{document}